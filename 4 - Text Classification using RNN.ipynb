{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import sys\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import tqdm\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filepath, lower=True):\n",
    "    tokens, labels = [], []\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            text, label = line.strip().split('\\t')\n",
    "            cur_tokens = word_tokenize(text, language='russian')\n",
    "            if lower:\n",
    "                cur_tokens = [token.lower() for token in cur_tokens]\n",
    "            labels.append(label)\n",
    "            tokens.append(cur_tokens)\n",
    "    \n",
    "    return Dataset.from_dict({'tokens': tokens, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_LOWER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac38b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DatasetDict()\n",
    "\n",
    "for split_name in ['train', 'validation', 'test']:\n",
    "    data[split_name] = read_dataset(f'data/sensitive_topics/{split_name}.tsv', lower=TEXT_LOWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf984df",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "special_tokens = ['<unk>', '<pad>']\n",
    "\n",
    "tokens_vocab = torchtext.vocab.build_vocab_from_iterator(data['train']['tokens'],\n",
    "                                                  min_freq=min_freq,\n",
    "                                                  specials=special_tokens)\n",
    "\n",
    "idx_to_label = list(set(data['train']['label']))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(idx_to_label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_index = tokens_vocab['<unk>']\n",
    "pad_index = tokens_vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843282aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_data(example, tokens_vocab, label_to_idx):\n",
    "    token_idxs = tokens_vocab.forward(example['tokens'])\n",
    "    label_idx = label_to_idx[example['label']]\n",
    "    return {'tokens': token_idxs, 'label': label_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = data.map(numericalize_data, fn_kwargs={'tokens_vocab': tokens_vocab,\n",
    "                                                          'label_to_idx': label_to_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b956558",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transformed_data.with_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53575424",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    batch_tokens = [example['tokens'] for example in batch]\n",
    "    batch_labels = torch.stack([example['label'] for example in batch])\n",
    "    batch_tokens = nn.utils.rnn.pad_sequence(batch_tokens, padding_value=tokens_vocab['<pad>'], batch_first=True)\n",
    "    batch = {'tokens': batch_tokens,\n",
    "             'label': batch_labels}\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(transformed_data['train'], \n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               collate_fn=collate_batch, \n",
    "                                               shuffle=True)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(transformed_data['validation'],\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    collate_fn=collate_batch)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(transformed_data['test'],\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebad518",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53427b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional,\n",
    "                 dropout_rate, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n",
    "                            dropout=dropout_rate, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, ids):\n",
    "        # ids = [batch size, seq len]\n",
    "        # length = [batch size]\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # output = [batch size, seq len, hidden dim * n directions]\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
    "            # hidden = [batch size, hidden dim * 2]\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "            # hidden = [batch size, hidden dim]\n",
    "        prediction = self.fc(hidden)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11206188",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokens_vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "output_dim = len(idx_to_label)\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n",
    "             pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a780705",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8302f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    for batch in tqdm.tqdm(dataloader, desc='training...', file=sys.stdout):\n",
    "        ids = batch['tokens'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        prediction = model(ids)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "\n",
    "    return epoch_losses, epoch_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7988786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, device):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(dataloader, desc='evaluating...', file=sys.stdout):\n",
    "            ids = batch['tokens'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            prediction = model(ids)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "\n",
    "    return epoch_losses, epoch_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66535bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c05b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, device)\n",
    "    valid_loss, valid_acc = evaluate(validation_dataloader, model, criterion, device)\n",
    "\n",
    "    train_losses.extend(train_loss)\n",
    "    train_accs.extend(train_acc)\n",
    "    valid_losses.extend(valid_loss)\n",
    "    valid_accs.extend(valid_acc)\n",
    "    \n",
    "    epoch_train_loss = np.mean(train_loss)\n",
    "    epoch_train_acc = np.mean(train_acc)\n",
    "    epoch_valid_loss = np.mean(valid_loss)\n",
    "    epoch_valid_acc = np.mean(valid_acc)\n",
    "    \n",
    "    if epoch_valid_loss < best_valid_loss:\n",
    "        best_valid_loss = epoch_valid_loss\n",
    "        torch.save(model.state_dict(), 'lstm.pt')\n",
    "    \n",
    "    print(f'epoch: {epoch+1}')\n",
    "    print(f'train_loss: {epoch_train_loss:.3f}, train_acc: {epoch_train_acc:.3f}')\n",
    "    print(f'valid_loss: {epoch_valid_loss:.3f}, valid_acc: {epoch_valid_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(train_losses, label='train loss')\n",
    "ax.plot(valid_losses, label='valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(train_accs, label='train accuracy')\n",
    "ax.plot(valid_accs, label='valid accuracy')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('lstm.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\n",
    "\n",
    "epoch_test_loss = np.mean(test_loss)\n",
    "epoch_test_acc = np.mean(test_acc)\n",
    "\n",
    "print(f'test_loss: {epoch_test_loss:.3f}, test_acc: {epoch_test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07df383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(text, model, tokens_vocab, idx_to_label, device, lower=True):\n",
    "    tokens = word_tokenize(text, language='russian')\n",
    "    ids = tokens_vocab.forward(tokens)\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_idx = prediction.argmax(dim=-1).item()\n",
    "    predicted_class = idx_to_label[predicted_idx]\n",
    "    predicted_probability = probability[predicted_idx].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Все ложь, макаронного монстра не существует, пастафарианство было ошибкой!'\n",
    "\n",
    "process_line(text, model, tokens_vocab, idx_to_label, device, TEXT_LOWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Я куплю арбалет и пойду охотиться на единорогов!'\n",
    "\n",
    "process_line(text, model, tokens_vocab, idx_to_label, device, TEXT_LOWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b029fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
